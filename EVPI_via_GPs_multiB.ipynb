{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform VoI calculation using GP surrogate over join action-uncertainty space for multiple buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats import qmc\n",
    "import sklearn.gaussian_process as gp\n",
    "import scipy.optimize as op\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "import inspect\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [48,32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base parameters.\n",
    "dataset_dir = os.path.join('data','A37_analysis_test') # dataset directory\n",
    "opex_factor = 10\n",
    "pricing_dict = {'carbon':5e-1,'battery':1e3,'solar':2e3}\n",
    "with open(os.path.join(dataset_dir,'metadata_ext.json'),'r') as json_file:\n",
    "        annex_defaults = json.load(json_file)\n",
    "base_kwargs = {\n",
    "    'output_dir_path': dataset_dir,\n",
    "    'building_names': ['UCam_Building_%s'%id for id in ids],\n",
    "    'battery_energy_capacities': None,\n",
    "    'battery_power_capacities': [annex_defaults[\"building_attributes\"][\"battery_power_capacities (kW)\"][str(id)] for id in ids],\n",
    "    'battery_efficiencies': None,\n",
    "    'pv_power_capacities': None,\n",
    "    'load_data_paths': ['UCam_Building_%s.csv'%id for id in ids],\n",
    "    'weather_data_path': 'weather.csv',\n",
    "    'carbon_intensity_data_path': 'carbon_intensity.csv',\n",
    "    'pricing_data_path': 'pricing.csv',\n",
    "    'schema_name': 'schema_temp'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiprocessing helper functions.\n",
    "\n",
    "n_processes = min(25,os.cpu_count()//2) # for some reason more than this is an issue ...? Maybe a memory issue\n",
    "\n",
    "def multi_proc_constr_and_eval_system(args_list):\n",
    "\n",
    "    from sys_eval import construct_and_evaluate_system\n",
    "\n",
    "    return construct_and_evaluate_system(*args_list)\n",
    "\n",
    "def parallel_task(func, iterable, n_procs):\n",
    "    # Adapted from solution to https://stackoverflow.com/questions/47313732/jupyter-notebook-never-finishes-processing-using-multiprocessing-python-3/47374811\n",
    "    # NOTE: this function must be in the notebook\n",
    "    # NOTE: in this workaround, the function passed to `parallel_task`\n",
    "    # must do all of the importing it needs, and unwrap the arguments\n",
    "    # (only a single argument can be passed)\n",
    "\n",
    "    temp_path = f'./tmp_func.py'\n",
    "    with open(temp_path, 'w') as file:\n",
    "        file.write(inspect.getsource(func).replace(func.__name__, \"task\"))\n",
    "\n",
    "    from tmp_func import task\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        pool = Pool(processes=n_procs)\n",
    "        res = list(tqdm(pool.imap(task, iterable), total=len(iterable)))\n",
    "        pool.close()\n",
    "        os.remove(temp_path)\n",
    "        return res\n",
    "    else:\n",
    "        raise \"Not in Jupyter Notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Train GP Surrogate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: probably sensible to conduct an initial rough space search to identify sensible bounds as we expect the objective (cost) to be behaviour reasonably nicely, at least far from the region of the optimum.\n",
    "The smaller the bounded region the better the surrogate will be and the easier the global optimisation will be - however as these bounds are arbitrary, if we encounter boundary solutions, the bounds need to be extended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remeber to note Dom's alternative suggestion for learning a surrogate, and it's motivation from the smoothness of his posterior solution results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sampling of action-uncertainty space\n",
    "seed = 42\n",
    "n_samples = 10000 # increase for final results?\n",
    "\n",
    "# Space filling sampling of action sub-space using Latin Hypercube\n",
    "lower_bounds = np.array([*[1e3,3e2],*[8e2,1e2]])\n",
    "upper_bounds = np.array([*[1.4e3,7e2],*[1.2e3,5e2]])\n",
    "\n",
    "action_sampler = qmc.LatinHypercube(d=len(ids)*2)\n",
    "action_samples = action_sampler.random(n=n_samples)\n",
    "action_samples = qmc.scale(action_samples, lower_bounds, upper_bounds)\n",
    "\n",
    "# Sample from prior distributions of uncertain parameters\n",
    "mu = 0.85\n",
    "sigma = 0.1\n",
    "eta_samples = np.random.normal(loc=mu,scale=sigma,size=(n_samples,len(ids)))\n",
    "eta_samples = np.clip(eta_samples,0,1)\n",
    "\n",
    "# Combine samples from two sub-spaces\n",
    "space_samples = np.hstack([action_samples,eta_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate system cost over samples. (Old serial implementation)\n",
    "# costs = []\n",
    "# for n in tqdm(range(n_samples)):\n",
    "#     cost = construct_and_evaluate_system(action_samples[n][:len(ids)],action_samples[n][len(ids):],eta_samples[n],base_kwargs,pricing_dict,opex_factor)\n",
    "#     costs.append(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate system cost over samples. (Parallelised)\n",
    "mproc_args_list = [[action_samples[n][:len(ids)],action_samples[n][len(ids):],eta_samples[n],base_kwargs,pricing_dict,opex_factor,n] for n in range(n_samples)]\n",
    "space_sample_costs = parallel_task(multi_proc_constr_and_eval_system, mproc_args_list, n_procs=n_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GP training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Gaussian Process surrogate.\n",
    "\n",
    "length_scale_init_guess = [*[50]*len(ids),*[40]*len(ids),*[0.1]*len(ids)]\n",
    "kernel = 1 * gp.kernels.RBF(length_scale=np.array(length_scale_init_guess))\n",
    "gp_surrogate = gp.GaussianProcessRegressor(kernel=kernel,normalize_y=True, n_restarts_optimizer=5)\n",
    "start = time.time()\n",
    "gp_surrogate.fit(space_samples, space_sample_costs)\n",
    "end = time.time()\n",
    "gp_surrogate.kernel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"GP surrogate training time: {round(end-start,1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE!!! Training the GP properly seems to be a bit of an issue - the length scales that comes out of the optimiser are sometimes completely off - having a good initialisation to the optimisation seems important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_prediction, std_prediction = gp_surrogate.predict(space_samples, return_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Solve Prior Problem using Surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fn for system cost predicted by surrogate.\n",
    "def single_surrogate_estimate(x, surrogate, eta):\n",
    "\n",
    "    assert len(x) % 2 == 0, \"Design variable argument must have even length.\"\n",
    "\n",
    "    predict_point = np.hstack([x,np.array(eta)])\n",
    "    mean_prediction = surrogate.predict(predict_point)\n",
    "\n",
    "    return mean_prediction\n",
    "\n",
    "# Define fn of mean system cost predicted by surrogate.\n",
    "def mean_cost_surrogate_estimate(x, surrogate, n_MC_samples, eta_mu, eta_sigma):\n",
    "\n",
    "    assert len(x) % 2 == 0, \"Design variable argument must have even length.\"\n",
    "\n",
    "    # Make draw from distribution of uncertainties - specified in args (mu, sigma)\n",
    "    # ========================================================================\n",
    "    eta_samples = np.random.normal(loc=eta_mu,scale=eta_sigma,size=(n_MC_samples,len(ids)))\n",
    "    eta_samples = np.clip(eta_samples,0,1)\n",
    "\n",
    "    # Predict costs for each efficiency sample at target point using surrogate\n",
    "    # ========================================================================\n",
    "    predict_points = np.hstack([np.tile(x,(n_MC_samples,1)),eta_samples])\n",
    "    mean_prediction = surrogate.predict(predict_points)\n",
    "\n",
    "    return np.mean(mean_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = op.Bounds(lb=lower_bounds,ub=upper_bounds)\n",
    "n_surrogate_MC_samples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "prior_soln = op.differential_evolution(mean_cost_surrogate_estimate, bounds, args=(gp_surrogate,n_surrogate_MC_samples,mu,sigma), seed=seed)\n",
    "end = time.time()\n",
    "print(prior_soln.x, prior_soln.fun, prior_soln.nfev, prior_soln.message)\n",
    "prior_design = prior_soln.x\n",
    "prior_cost = prior_soln.fun\n",
    "print(f\"Prior solution: {prior_design}\")\n",
    "print(f\"Predicted prior solution cost: {round(prior_cost,2)}\")\n",
    "print(f\"Prior problem solve time: {round(end-start,1)}\")\n",
    "print(prior_soln.nfev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test quality of surrogate prior optimal solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_MC_samples = 500\n",
    "eta_samples = np.random.normal(loc=mu,scale=sigma,size=(n_MC_samples,len(ids)))\n",
    "eta_samples = np.clip(eta_samples,0,1)\n",
    "\n",
    "# sample_costs = []\n",
    "# for eta_sample in tqdm(eta_samples):\n",
    "#     sample_cost = construct_and_evaluate_system(prior_design[:len(ids)],prior_design[len(ids):],eta_sample,base_kwargs,pricing_dict,opex_factor)\n",
    "#     sample_costs.append(sample_cost)\n",
    "mproc_args_list = [[prior_design[:len(ids)],prior_design[len(ids):],eta_samples[n],base_kwargs,pricing_dict,opex_factor,n] for n in range(n_MC_samples)]\n",
    "sample_costs = parallel_task(multi_proc_constr_and_eval_system, mproc_args_list, n_procs=n_processes)\n",
    "\n",
    "true_prior_soln_cost_estimate = np.mean(sample_costs)\n",
    "\n",
    "print(f\"True prior solution cost: {round(true_prior_soln_cost_estimate,2)}\")\n",
    "print(f\"Surrogate prior optimal solution fn error: {round(np.abs(true_prior_soln_cost_estimate-prior_cost),2)},\\\n",
    "    {round((np.abs(true_prior_soln_cost_estimate-prior_cost)/true_prior_soln_cost_estimate)*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare absolute error to MC estimate standard error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.std(sample_costs)/np.sqrt(len(sample_costs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Solve Pre-Posterior Problem using Surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from prior distribution of uncertainties.\n",
    "n_prior_samples = 500\n",
    "prior_eta_samples = np.random.normal(loc=mu,scale=sigma,size=(n_prior_samples,len(ids)))\n",
    "prior_eta_samples = np.clip(prior_eta_samples,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_optimal_results = []\n",
    "prior_soln_performances = []\n",
    "\n",
    "# Solve posterior problem for each eta sample.\n",
    "for eta_sample in tqdm(prior_eta_samples):\n",
    "    posterior_soln = op.differential_evolution(single_surrogate_estimate, bounds, args=(gp_surrogate,eta_sample), seed=seed)\n",
    "    posterior_optimal_results.append(posterior_soln)\n",
    "    #print(eta_sample, posterior_soln.x, posterior_soln.fun, posterior_soln.message)\n",
    "\n",
    "    # check surrogate predicted performance (cost) of prior solution for posterior given sampled eta value\n",
    "    prior_soln_eta_cost = single_surrogate_estimate(prior_design,gp_surrogate,eta_sample)\n",
    "    prior_soln_performances.append(prior_soln_eta_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preposterior_costs = [res.fun for res in posterior_optimal_results]\n",
    "preposterior_cost = np.mean(preposterior_costs)\n",
    "print(\"Pre-posterior cost: %s\"%preposterior_cost)\n",
    "print(\"Prior cost check: \",np.mean(prior_soln_performances),prior_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The two methods of calculating prior solution cost return quite different values - which one is better to use? Potentially the one computed using the nested expectations as it uses the same posterior cost curve estimates (from the surrogate) that is used for the posterior optimisation. But on the other hand, the first method is one used to determine the prior solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convergence of pre-posterior cost MC estimate.\n",
    "\n",
    "MC_means = [np.mean(preposterior_costs[:i]) for i in range(1,n_prior_samples+1)]\n",
    "MC_stnd_errors = [np.std(preposterior_costs[:i])/np.sqrt(i) for i in range(2,n_prior_samples+1)]\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_xlim(1,n_prior_samples)\n",
    "ax.set_xlabel(\"Number of samples\")\n",
    "ax.grid(True,'major',alpha=0.5,linestyle='--')\n",
    "\n",
    "ax.plot(range(1,n_prior_samples+1),np.array(MC_means)/1e6,'-k')\n",
    "ax.set_ylabel('Pre-posterior cost estimate (£m)')\n",
    "#ax.set_ylim(0)\n",
    "\n",
    "# min_ax = ax.twinx()\n",
    "# min_ax.plot(range(2,n_draws+1),(np.array(MC_stnd_errors)/MC_means[-1])*100,'k--')\n",
    "# min_ax.set_ylabel('Estimate standard error (% of final mean)')\n",
    "# min_ax.set_ylim(0)\n",
    "\n",
    "min_ax_abs = ax.twinx()\n",
    "min_ax_abs.plot(range(2,n_prior_samples+1),np.array(MC_stnd_errors)/1e3,'k:')\n",
    "min_ax_abs.set_ylabel('Estimate standard error (£k)')\n",
    "min_ax_abs.set_ylim(0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test quality of surrogate posterior optimal solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - this calculation is extremely hefty! However, we can use a random sub-sample of solutions to estimate mean quality (note solutions are already randomly ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mproc_args_list = []\n",
    "for i, (posterior_result,eta_sample) in enumerate(zip(posterior_optimal_results,prior_eta_samples)):\n",
    "    mproc_args_list.append([posterior_result.x[:len(ids)],posterior_result.x[len(ids):],eta_sample,base_kwargs,pricing_dict,opex_factor,i])\n",
    "true_posterior_soln_cost = parallel_task(multi_proc_constr_and_eval_system, mproc_args_list, n_procs=n_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted posterior solution costs: \",preposterior_costs)\n",
    "print(\"Estimates of true posterior solution costs: \",true_posterior_soln_cost)\n",
    "mean_posterior_soln_fn_error = np.mean(np.abs(np.array(true_posterior_soln_cost)-np.array(preposterior_costs)))\n",
    "mean_posterior_soln_fn_error_perc = np.mean((np.abs(np.array(true_posterior_soln_cost)-np.array(preposterior_costs))/np.array(true_posterior_soln_cost))*100)\n",
    "print(f\"Surrogate mean posterior optimal solution fn error: {round(mean_posterior_soln_fn_error,2)}, {round(mean_posterior_soln_fn_error_perc,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph posterior solution error results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Report VOI Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the standard error on the pre-posterior cost MC estimate as an error for result reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"VOI: %s\"%round(prior_cost-preposterior_cost,2))\n",
    "print(\"plus-minus: %s\"%round(np.std(preposterior_costs)/np.sqrt(n_prior_samples),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prior_cost,preposterior_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prior cost check: \",np.mean(prior_soln_performances),prior_cost)\n",
    "print(\"Regret based VoI: \",round((np.mean(prior_soln_performances)-preposterior_cost),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VOI-CAS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
